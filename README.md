 # 주제   
신용카드 이상거래 탐지모델 개발     

# 데이터탐색     
* 정상거래인 0과 이상거래인 1의 차이가 매우 심한 불균형데이터     

# 초기 모델링    

| model	| precision_test	| recall_test |	f1_score_test |    
| ----- | ----- | ----- | ----- |
| 0	| MLP	| 0.87	| 0.81	| 0.84 |      
| 1	| LightGBM	| 0.94	| 0.82	| 0.87 |      
| 2	| ANN	| 0.80	| 0.82	| 0.81 |        
| 3	| Random Forest	| 0.90	| 0.80	| 0.85 |      
| 4	| XGBoost	| 0.95	| 0.81	| 0.87 |     
| 5	| Decision Tree	| 0.80	| 0.78	| 0.79 |     
| 6	| AdaBoost	| 0.84	| 0.78	| 0.80 |     
| 7	| KNeighbors	| 0.88	| 0.78	| 0.83 |      
| 8	| Logistic Regression	| 0.89	| 0.71	| 0.79 |      
| 9	| SVM	| 0.92	| 0.68	| 0.78 |      
| 10	| Gradient Boost	| 0.62	| 0.15	| 0 |        

* 가장 성능이 높은 XGBoost와 LGBMClassifier 모델을 통한 추가적인 모델링 진행     
 
# Under_Over Sampling 비교     

| model	| accuracy	| precision	recall	| f1_score	| roc_auc |     
| ----- | ----- | ----- | ----- | ----- |
| 0	| XGboost_under	| 0.13	| 0.00	| 0.99	| 0.56	| 0.56 |
| 1	| Xgboost_over	| 1.00	| 0.95	| 0.93	| 0.97	| 0.97 |   
| 2	| LightGBM_over	| 1.00	| 0.92	| 0.92	| 0.96	| 0.96 |      
| 3	| LightGBM_under	| 0.40	| 0.00	| 0.90	| 0.65	| 0.65 |           

# 결론     
* SMOTE 적용: 불균형 데이터셋에 SMOTE를 적용해 레이블 불균형(사기 거래보다 정상 거래가 더 많음)을 해결함.     
* 모델 성능 차이: 오버 샘플링된 데이터셋에서 신경망이 무작위 언더샘플링 데이터셋을 사용하는 모델 보다 사기 거래를 올바르게 예측하는 경우가 적었음.     
* 정상 거래 오탐지: 언더샘플링 데이터에서는 많은 정상 거래를 사기 거래로 잘못 분류하는 문제가 발생함. 이는 고객 불만과 금융 기관의 단점으로 어이질 수 있음.     
* 데이터 셔플링: 데이터 셔플링을 구현했기 때문에 예측과 정확도가 변동될 수 있음.     
